{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once, to solve the conflict with ROS\n",
    "import sys\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points\n",
    "nx = 9 # TODO: enter the number of inside corners in x\n",
    "ny = 6 # TODO: enter the number of inside corners in y\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And so on and so forth..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply a distortion correction to raw images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distortion function\n",
    "# Write a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1:], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "# Step through the list and search for chessboard corners\n",
    "for x in os.listdir(\"test_images/\"):\n",
    "    input_path = \"test_images/\" + x\n",
    "    if os.path.isdir(input_path):\n",
    "        continue\n",
    "    \n",
    "    # Read in each raw image\n",
    "    raw_img = cv2.imread(input_path)\n",
    "    \n",
    "    # 2. Apply a distortion correction to raw images.\n",
    "    undistorted = cal_undistort(raw_img, objpoints, imgpoints)\n",
    "    # 3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    # 4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "    # 5. Detect lane pixels and fit to find the lane boundary.\n",
    "    # 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "    # 7. Warp the detected lane boundaries back onto the original image.\n",
    "    # 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "    # Select output_image\n",
    "    output_image = undistorted\n",
    "    \n",
    "    # Show output image\n",
    "    cv2.imshow('undistorted',output_image)\n",
    "    cv2.waitKey(500)\n",
    "    \n",
    "    # Outout the image to directory \"/test_image_output\"\n",
    "    output_path = \"test_image_output/\" + x\n",
    "    if os.path.isdir(output_path):\n",
    "        continue\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "    \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use color transforms, gradients, etc., to create a thresholded binary image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help functions\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x or y gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # Return the result\n",
    "    return binary_output\n",
    "\n",
    "def mag_threshold(img, sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh[0]) & (gradmag <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradients threshold combined function\n",
    "def gradients_threshold(image, ksize=15, x_thresh=(20, 255), y_thresh=(20, 255), mag_thresh=(30, 255), dir_thresh=(0.7, 1.3)):\n",
    "    # Choose a Sobel kernel size\n",
    "    # Choose a larger odd number to smooth gradient measurements\n",
    "    \n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=x_thresh)\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=y_thresh)\n",
    "    mag_binary = mag_threshold(image, sobel_kernel=ksize, thresh=mag_thresh)\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=dir_thresh) \n",
    "    \n",
    "    # Combine the pixels where: \n",
    "    #     both the xx and yy gradients meet the threshold criteria\n",
    "    #   or \n",
    "    #     the gradient magnitude and direction are both within their threshold values\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color transforms combined function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of calibration images\n",
    "# Step through the list and search for chessboard corners\n",
    "for x in os.listdir(\"test_images/\"):\n",
    "    input_path = \"test_images/\" + x\n",
    "    if os.path.isdir(input_path):\n",
    "        continue\n",
    "    \n",
    "    # Read in each raw image\n",
    "    raw_img = cv2.imread(input_path)\n",
    "    \n",
    "    # 2. Apply a distortion correction to raw images.\n",
    "    undistorted = cal_undistort(raw_img, objpoints, imgpoints)\n",
    "    # 3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "    ksize=15\n",
    "    x_thresh=(20, 255)\n",
    "    y_thresh=(20, 255)\n",
    "    mag_thresh=(30, 255)\n",
    "    dir_thresh=(0.7, 1.3)\n",
    "    grad_threshed = gradients_threshold(undistorted, ksize, x_thresh, y_thresh, mag_thresh, dir_thresh)\n",
    "    # 4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "    # 5. Detect lane pixels and fit to find the lane boundary.\n",
    "    # 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "    # 7. Warp the detected lane boundaries back onto the original image.\n",
    "    # 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "    # Select output_image\n",
    "    output_image = grad_threshed\n",
    "    \n",
    "    # Show output image\n",
    "    cv2.imshow('undistorted',output_image)\n",
    "    cv2.waitKey(500)\n",
    "    \n",
    "    # Outout the image to directory \"/test_image_output\"\n",
    "    output_path = \"test_image_output/\" + x\n",
    "    if os.path.isdir(output_path):\n",
    "        continue\n",
    "    cv2.imwrite(output_path, output_image)\n",
    "    \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply a perspective transform to rectify binary image (\"birds-eye view\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undistort and Unwarp the raw image\n",
    "    top_down, perspective_M = corners_unwarp(undistorted, nx, ny, mtx, dist)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(raw_img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(top_down)\n",
    "    ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detect lane pixels and fit to find the lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
